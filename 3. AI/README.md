# AI 강의 1차
![1013-1](./1013-1.png)
![1013-2](./1013-2.png)



# AI 강의 2차
![1014-1](./1014-1.png)
![1014-2](./1014-2.png)

1. 단순선형회귀
![1014-1](./1014-1.png)
![1014-2](./1014-2.png)
![1014-3](./1014-3.png)
![1014-4](./1014-4.png)
![1014-5](./1014-5.png)
![1014-6](./1014-6.png)

2. 로지스틱 
![1014-7](./1014-7.png)
![1014-8](./1014-8.png)
![1014-9](./1014-9.png)


3. Shallow network  (앝은 신경망)
![1014-10](./1014-10.png)
![1014-11](./1014-11.png)
![1014-12](./1014-12.png)
![1014-13](./1014-13.png)
![1014-14](./1014-14.png)
![1014-15](./1014-15.png)

- Shallow: 숨은층(히든 레이어)이 1개.
- Deep: 숨은층이 여러 개(보통 3개 이상을 deep이라 부름).


4. Deep network (다 신경망)

- 히든레이어 없이 직접연결? 
- 과적합(오버피팅) 위험↓, 가볍고 해석 가능하며 안정적입니다. 다만 표현력이 낮아 데이터가 복잡할수록 한계가 빨리 와요.
![1014-16](./1014-16.png)
![1014-17](./1014-17.png)

## (결과) 많아질수록, 유연한 곡선이 도출
5. 손실함수
![1014-18](./1014-18.png)
* 이후 드랍 